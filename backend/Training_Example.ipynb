{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "PADDING_TOKEN = '<PAD>'\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 2\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "max_sequence_length = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flutter Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 29119\n"
     ]
    }
   ],
   "source": [
    "from pygments.lexers import DartLexer\n",
    "from utils.vocab import dart_vocab\n",
    "from utils.code_tokenizer import CodeTokenizer\n",
    "\n",
    "flutter_tokenizer = CodeTokenizer(\n",
    "    DartLexer(),\n",
    "    framework_vocab=[\"Scaffold\", \"Widget\", \"setState\"],\n",
    "    language_vocab=dart_vocab,\n",
    "    START_TOKEN=START_TOKEN,\n",
    "    END_TOKEN=END_TOKEN,\n",
    "    PAD_TOKEN=PADDING_TOKEN\n",
    ")\n",
    "\n",
    "print(f\"Token Count: {len(flutter_tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create React Native Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 29121\n"
     ]
    }
   ],
   "source": [
    "from pygments.lexers import JavascriptLexer\n",
    "from utils.vocab import javascript_vocab\n",
    "from utils.code_tokenizer import CodeTokenizer\n",
    "\n",
    "react_native_tokenizer = CodeTokenizer(\n",
    "    JavascriptLexer(),\n",
    "    framework_vocab=[\"View\", \"Text\", \"useState\"],\n",
    "    language_vocab=javascript_vocab,\n",
    "    START_TOKEN=START_TOKEN,\n",
    "    END_TOKEN=END_TOKEN,\n",
    "    PAD_TOKEN=PADDING_TOKEN,\n",
    ")\n",
    "\n",
    "print(f\"Token Count: {len(react_native_tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Letter Tokenizer\n",
    "For debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 100\n"
     ]
    }
   ],
   "source": [
    "from utils.code_tokenizer import CodeTokenizer\n",
    "\n",
    "letter_tokenizer = CodeTokenizer(\n",
    "    None,\n",
    "    framework_vocab=[],\n",
    "    language_vocab=[\n",
    "        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "        'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'\n",
    "        '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '{', '}', '(', ')',\n",
    "        '[', ']', '=', '+', '-', '*', '/', '%', '^', '&', '|', '!', '?', '<',\n",
    "        '>', ':', ';', ',', '.', '_', '#', '@', '$', '~', '`', '\"', \"'\", '\\\\',\n",
    "        '/', '\\n', ' ', '\\t', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "        'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "        'W', 'X', 'Y', 'Z'\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Token Count: {len(letter_tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SnippetEmbedding(\n",
       "      (embedding): Embedding(29119, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SnippetEmbedding(\n",
       "      (embedding): Embedding(29121, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm3): LayerNormalization()\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=29121, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.transformer import Transformer\n",
    "\n",
    "transformer = Transformer(\n",
    "    d_model, \n",
    "    ffn_hidden,\n",
    "    num_heads, \n",
    "    drop_prob, \n",
    "    num_layers, \n",
    "    max_sequence_length,\n",
    "    flutter_tokenizer,\n",
    "    react_native_tokenizer,\n",
    ")\n",
    "\n",
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, a_snippets, a_parser, b_snippets, b_parser):\n",
    "        self.a_snippets = a_snippets\n",
    "        self.a_parser = a_parser\n",
    "        self.b_snippets = b_snippets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.a_snippets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.a_snippets[idx], self.b_snippets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dart samples: 212\n",
      "Number of JS samples: 212\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.parsing.code_parser import DartParser, JavascriptParser\n",
    "\n",
    "df = pd.read_csv('./data/raw/samples.csv')\n",
    "\n",
    "dart_samples = df['dart'].values\n",
    "js_samples = df['javascript'].values\n",
    "\n",
    "# filter for max length of sample at `max_sequence_len`` characters for training purposes\n",
    "zipped = list(zip(dart_samples, js_samples))\n",
    "samples = [(d, j) for d, j in zipped]\n",
    "dart_samples, js_samples = zip(*samples)\n",
    "\n",
    "print(\"Number of Dart samples:\", len(dart_samples))\n",
    "print(\"Number of JS samples:\", len(js_samples))\n",
    "\n",
    "dataset = TextDataset(dart_samples, DartParser(), js_samples, JavascriptParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(ignore_index=react_native_tokenizer[PADDING_TOKEN], reduction='none')\n",
    "\n",
    "# When computing the loss, we are ignoring cases when the label is the padding token\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform_(params)\n",
    "\n",
    "optim = torch.optim.AdamW(transformer.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(flutter_batch, react_batch):\n",
    "    num_seqs = len(flutter_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_seqs, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_seqs, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_seqs, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_seqs):\n",
    "        flutter_sentence_length, react_sentence_length = len(flutter_batch[idx]), len(react_batch[idx])\n",
    "        flutter_tokens_to_padding_mask = np.arange(flutter_sentence_length + 1, max_sequence_length)\n",
    "        react_tokens_to_padding_mask = np.arange(react_sentence_length + 1, max_sequence_length)\n",
    "        encoder_padding_mask[idx, :, flutter_tokens_to_padding_mask] = True\n",
    "        encoder_padding_mask[idx, flutter_tokens_to_padding_mask, :] = True\n",
    "        decoder_padding_mask_self_attention[idx, :, react_tokens_to_padding_mask] = True\n",
    "        decoder_padding_mask_self_attention[idx, react_tokens_to_padding_mask, :] = True\n",
    "        decoder_padding_mask_cross_attention[idx, :, flutter_tokens_to_padding_mask] = True\n",
    "        decoder_padding_mask_cross_attention[idx, react_tokens_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [26:42<00:00, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 4435.746726499201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        flutter_batch, react_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(flutter_batch, react_batch)\n",
    "        optim.zero_grad()\n",
    "        react_pred = transformer(\n",
    "            flutter_batch,\n",
    "            react_batch,\n",
    "            encoder_self_attention_mask.to(device), \n",
    "            decoder_self_attention_mask.to(device), \n",
    "            decoder_cross_attention_mask.to(device),\n",
    "        )\n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(react_batch)\n",
    "        loss = criterian(\n",
    "            react_pred.view(-1, len(react_native_tokenizer)).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "        valid_indicies = torch.where(labels.view(-1) == react_native_tokenizer[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "print(f\"Total Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double x = 1; double y = 2; double z = x + y; print(z);\n",
      "React Translation: <START><START>abstractabstractvar>'##ep##ep##T>##fi##fi##ub##ows##quence>abstract##tr##tre##pcleanedcleanede##pcleanedcleanedcleaned>cleanedcleaned^^##as##as##as##asbreak##ition##ition##itionnumbersnumbersZnumbersque##0>abstract##ricetankt##rcleanednumberst##reprefixprefixp##ase##ase##d##ase##aseprefixnumbersScpSc##reak##d##tre##tre##drepeatedrepeated##d>cleaned##ed##edheight##fit##fitnumbersnumbersabstractnumbersnumbersabstractnumbersnumbersabstractnumbersnumbers##do##thestnumbersnumbersnumbers##tringnumbersnumbersnumbers##tring##ition##ition##as##tring##metric##tringcleaned##tringprefixcleaned##tring##trackcleanedcleaned0>abstractcleanedcleanedprefix##ckcleanedcleanedcleanedrcleanedsequencesequence##umsequence##tsequencesequenceheight##p##resequence##x##p##resequence##x##pprefixprefixlocal##eprefixprefixpar##esequencesequencedsequencesequenceas##esequencesequencecomplementcleaned##resequence##xsequence##tring##S##c##p##S##csequencesequenceheight##ricesolutionsolutiondsequencesequencet##resequencesequencet##resequencesequenced##resequencesequence##resequencesequencesequencesequenced>cleanedeachsequencesequencerepeatedrepeatedrepeatedrepeatedrepeatedsequencesequencesequencesequencesequencehavehave##tringsequence##tringsequencesequence##fitsequence##tringsequence##tringsequencesequence##fitsequence##tring##as##tring##as##as##ctsequence##tringrepeated##tring##ostputputrepeatedrepeatedrepeated##strepeated##tringsequence##tringrepeated##tringsequencesequencet##ringsequence##ringsequence##ringsequence##tringsequencesequencet##ringcleanedcleanedcleanedshiftcleanedcleanedsequence##tringnumbersprefixabstractprefixprefixt##ring##ition##itionsequencesequencerepeatedt##ringrepeatedrepeated##dsequencesequencet##ring##p##rerepeated##xMin##itionheightsequencesequencet##ringsequencesequencesequenceprefixprefix##d##tanrepeated##d##rice>##list##listsequence##d##eacleanedheight##p##reunder##xundercleanedcsequencesequencerepeated##dsurroundedsurrounded##dnumberssequencesequenceprefixprefixprefix##ecleaned##1cleanedSuSu##m##seallallallt##1cleaned##1##victed##victed##ey##ey##listpcleanedcleanedre##1leafprefixprefixx3131pcleanedsequenceheight##secleanedcandycandyx##taprefixprefix##rerepeated##x##p##re##ey##x##run##alprefixsequencee##p##re##ies##x##p##re-=##xprefixcleanedcleanedcleaned##e31##13131##ecleaned##1cleaneddeltacleanedcleanedcleaned##ecleaned##se##ies##ies##tringprefixrepeatedrepeated##dprefixprefixre##1startsprefixprefixxsub>prefixprefixt##ringprefixprefix##fitprefixprefixcprefixprefixpprefixprefix##fitprefixprefixmid##secleanedsubcleanedprefixprefixprefixprefixprefixprefixprefixprefixvalueprefix##eprefix##1prefix##tprefixprefix##1sub##run##1##run##tprefix<END>\n"
     ]
    }
   ],
   "source": [
    "transformer.eval()\n",
    "# predict the translation of a flutter code snippet\n",
    "flutter_code = dart_samples[2]\n",
    "print(f\"double x = 1; double y = 2; double z = x + y; print(z);\")\n",
    "\n",
    "flutter_code = (flutter_code,)\n",
    "react_code = (\"\",)\n",
    "for word_counter in range(max_sequence_length):\n",
    "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(flutter_code, react_code)\n",
    "    predictions = transformer(\n",
    "        flutter_code,\n",
    "        react_code,\n",
    "        encoder_self_attention_mask.to(device), \n",
    "        decoder_self_attention_mask.to(device), \n",
    "        decoder_cross_attention_mask.to(device),\n",
    "    )\n",
    "    next_token_prob_distribution = predictions[0][word_counter]\n",
    "    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "    next_token = react_native_tokenizer.get_token(next_token_index)\n",
    "    react_code = (react_code[0] + next_token, )\n",
    "    if next_token == END_TOKEN:\n",
    "        break\n",
    "print(f\"React Translation: {react_code[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(transformer.state_dict(), './models/transformer.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
