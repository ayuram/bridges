{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Flutter Vocabulary: ['le', 'ss', ')', 'Container', 'package', 'Widget', 'StatelessWidget', ':', '!', 'F', 'setState', 'h', 't', 'AppBar', 'd', '{', 'v', 'ter', 'build', 'H', 'flutter', \"'\", 'f', 'context', 'Center', 'override', 'double', 'l', 's', 'pp', 'b', 'm', 'S', 'n', 'home', 'void', 'import', 'class', 'MyApp', 'return', 'c', 'Column', 'a', 'e', 'dart', '/', 'child', 'Text', 'B', 'y', 'ld', 'ontext', 'C', 'aterial', 'M', 'App', 'String', 'RaisedButton', 'u', 'Hello', 'bool', 'w', '(', '}', 'i', 'o', 'lutter', '@', 'Flutter', '.', ';', 'Bar', 'material', 'ild', 'uild', 'BuildContext', 'Scaffold', 'world', 'te', 'appBar', 'int', 'id', ',', 'exte', 'MaterialApp', 'r', 'body', 'or', 'extends', 'Row', 'title']\n",
      "Final React Native Vocabulary: ['render', 'le', '<', 'export', ')', '-', ':', '!', 'ress', 'j', 'React', 'Component', 'create', 't', 'd', 'ex', '{', 'v', 'I', 'H', '>', 'from', 'constructor', 'Button', 'SafeAreaView', \"'\", 'f', 'l', 's', 'native', 'm', '=', 'container', 'n', 'ti', 'ScrollView', 'import', 'class', 'return', 'e', 'c', 'flex', 'a', 'pressed', '/', 'alert', 'Text', 'FlatList', 'View', 'y', 'const', 'C', 'g', 'useEffect', 'App', 'x', 're', 'u', 'Hello', 'Press', 'w', '(', 'R', 'react', 'st', '}', 'i', 'act', 'on', 'center', 'TouchableOpacity', '\"', 'o', 'p', 'alignItems', 'justifyContent', ';', 'useState', '.', 'default', 'style', 'me', 'world', 'te', 'StyleSheet', 'port', ',', 'onPress', 'r', 'styles', 'or', 'title', '1']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Step 1: Gather Flutter and React Native keywords\n",
    "flutter_keywords = [\n",
    "    'class', 'import', 'void', 'int', 'String', 'double', 'bool', 'Widget', 'setState',\n",
    "    'build', 'context', 'Container', 'Column', 'Row', 'Text', 'RaisedButton', 'Scaffold', 'AppBar'\n",
    "]\n",
    "\n",
    "react_native_keywords = [\n",
    "    'import', 'from', 'class', 'constructor', 'render', 'return', 'Component', 'useState', 'useEffect',\n",
    "    'View', 'Text', 'Button', 'StyleSheet', 'TouchableOpacity', 'FlatList', 'ScrollView', 'SafeAreaView'\n",
    "]\n",
    "\n",
    "# Step 2: Basic tokenizer for the corpus\n",
    "def basic_tokenizer(text: str) -> List[str]:\n",
    "    tokens = re.findall(r'\\w+|\\S', text)\n",
    "    return tokens\n",
    "\n",
    "# Step 3: Extract tokens and initialize the vocabulary with keywords\n",
    "def initialize_vocabulary(corpus: List[str], keywords: List[str]) -> List[str]:\n",
    "    vocabulary = set(keywords)\n",
    "    for text in corpus:\n",
    "        tokens = basic_tokenizer(text)\n",
    "        vocabulary.update(tokens)\n",
    "    return list(vocabulary)\n",
    "\n",
    "# Step 4: Implement BPE to refine the vocabulary\n",
    "def get_stats(vocab: Dict[str, int]) -> Dict[Tuple[str, str], int]:\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols) - 1):\n",
    "            pairs[symbols[i], symbols[i + 1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair: Tuple[str, str], vocab: Dict[str, int]) -> Dict[str, int]:\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in vocab:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = vocab[word]\n",
    "    return v_out\n",
    "\n",
    "def byte_pair_encoding(corpus: List[str], num_merges: int) -> List[str]:\n",
    "    vocab = collections.Counter()\n",
    "    for text in corpus:\n",
    "        tokens = basic_tokenizer(text)\n",
    "        for token in tokens:\n",
    "            vocab[' '.join(token)] += 1\n",
    "\n",
    "    for i in range(num_merges):\n",
    "        pairs = get_stats(vocab)\n",
    "        if not pairs:\n",
    "            break\n",
    "        best = max(pairs, key=pairs.get)\n",
    "        vocab = merge_vocab(best, vocab)\n",
    "\n",
    "    bpe_vocab = set()\n",
    "    for word in vocab:\n",
    "        bpe_vocab.update(word.split())\n",
    "\n",
    "    return list(bpe_vocab)\n",
    "\n",
    "# Example usage\n",
    "flutter_corpus = [\n",
    "    \"\"\"import 'package:flutter/material.dart';\n",
    "    class MyApp extends StatelessWidget {\n",
    "      @override\n",
    "      Widget build(BuildContext context) {\n",
    "        return MaterialApp(\n",
    "          home: Scaffold(\n",
    "            appBar: AppBar(title: Text('Flutter App')),\n",
    "            body: Center(child: Text('Hello, world!')),\n",
    "          ),\n",
    "        );\n",
    "      }\n",
    "    }\"\"\"\n",
    "]\n",
    "\n",
    "react_native_corpus = [\n",
    "    \"\"\"import React from 'react';\n",
    "    import { View, Text, Button, StyleSheet } from 'react-native';\n",
    "\n",
    "    const App = () => {\n",
    "      return (\n",
    "        <View style={styles.container}>\n",
    "          <Text>Hello, world!</Text>\n",
    "          <Button title=\"Press me\" onPress={() => alert('Button pressed')} />\n",
    "        </View>\n",
    "      );\n",
    "    };\n",
    "\n",
    "    const styles = StyleSheet.create({\n",
    "      container: {\n",
    "        flex: 1,\n",
    "        justifyContent: 'center',\n",
    "        alignItems: 'center',\n",
    "      },\n",
    "    });\n",
    "\n",
    "    export default App;\"\"\"\n",
    "]\n",
    "\n",
    "# Initialize vocabulary with keywords\n",
    "flutter_vocabulary = initialize_vocabulary(flutter_corpus, flutter_keywords)\n",
    "react_native_vocabulary = initialize_vocabulary(react_native_corpus, react_native_keywords)\n",
    "\n",
    "# Apply BPE to further refine the vocabulary\n",
    "flutter_bpe_vocabulary = byte_pair_encoding(flutter_corpus, 50)\n",
    "react_native_bpe_vocabulary = byte_pair_encoding(react_native_corpus, 50)\n",
    "\n",
    "# Combine keywords and BPE tokens\n",
    "final_flutter_vocabulary = list(set(flutter_vocabulary).union(set(flutter_bpe_vocabulary)))\n",
    "final_react_native_vocabulary = list(set(react_native_vocabulary).union(set(react_native_bpe_vocabulary)))\n",
    "\n",
    "print(\"Final Flutter Vocabulary:\", final_flutter_vocabulary)\n",
    "print(\"Final React Native Vocabulary:\", final_react_native_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.utils.transformer import Transformer\n",
    "from utils.parser import react_native_vocab, flutter_vocab, START_TOKEN, END_TOKEN, PADDING_TOKEN\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 30\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "max_sequence_length = 200\n",
    "react_vocab_size = len(react_native_vocab)\n",
    "\n",
    "react_native_to_index = {word: i for i, word in enumerate(react_native_vocab)}\n",
    "flutter_to_index = {word: i for i, word in enumerate(flutter_vocab)}\n",
    "\n",
    "transformer = Transformer(d_model, \n",
    "                          ffn_hidden,\n",
    "                          num_heads, \n",
    "                          drop_prob, \n",
    "                          num_layers, \n",
    "                          max_sequence_length,\n",
    "                          react_vocab_size,\n",
    "                          flutter_to_index,\n",
    "                          react_native_to_index,\n",
    "                          START_TOKEN, \n",
    "                          END_TOKEN, \n",
    "                          PADDING_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SnippetEmbedding(\n",
       "      (embedding): Embedding(117, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SnippetEmbedding(\n",
       "      (embedding): Embedding(94, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm3): LayerNormalization()\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=94, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, flutter_snippets, react_snippets):\n",
    "        self.flutter_snippets = flutter_snippets\n",
    "        self.react_snippets = react_snippets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flutter_snippets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.flutter_snippets[idx], self.react_snippets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/raw/code.csv')\n",
    "\n",
    "dataset = TextDataset(df['dart'].values, df['js'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9',\n",
       " ')',\n",
       " 'interface',\n",
       " '!',\n",
       " 'do',\n",
       " 'function',\n",
       " 'catch',\n",
       " '\\t',\n",
       " 'of',\n",
       " '2',\n",
       " '6',\n",
       " 'abstract',\n",
       " 'typeof',\n",
       " '4',\n",
       " 'else',\n",
       " '=',\n",
       " 'finally',\n",
       " 'console',\n",
       " 'class',\n",
       " '~',\n",
       " 'continue',\n",
       " 'const',\n",
       " 'in',\n",
       " '(',\n",
       " ']',\n",
       " 'implements',\n",
       " 'with',\n",
       " '.',\n",
       " ';',\n",
       " 'default',\n",
       " 'public',\n",
       " 'private',\n",
       " ',',\n",
       " 'while',\n",
       " 'debugger',\n",
       " 'super',\n",
       " 'null',\n",
       " 'eval',\n",
       " '1',\n",
       " 'new',\n",
       " 'let',\n",
       " '<',\n",
       " 'export',\n",
       " 'package',\n",
       " '5',\n",
       " '-',\n",
       " ':',\n",
       " 'yield',\n",
       " 'true',\n",
       " '{',\n",
       " 'false',\n",
       " '\\n',\n",
       " '+',\n",
       " '>',\n",
       " '*',\n",
       " '0',\n",
       " '&',\n",
       " 'var',\n",
       " 'delete',\n",
       " 'protected',\n",
       " '[',\n",
       " 'await',\n",
       " 'enum',\n",
       " '3',\n",
       " 'for',\n",
       " 'void',\n",
       " 'instanceof',\n",
       " 'import',\n",
       " 'return',\n",
       " '/',\n",
       " 'log',\n",
       " 'this',\n",
       " '8',\n",
       " 'try',\n",
       " 'final',\n",
       " 'break',\n",
       " 'static',\n",
       " '7',\n",
       " ' ',\n",
       " '}',\n",
       " 'switch',\n",
       " '%',\n",
       " 'async',\n",
       " '|',\n",
       " 'if',\n",
       " 'throw',\n",
       " 'extends',\n",
       " 'case',\n",
       " 'arguments',\n",
       " '?',\n",
       " '<START>',\n",
       " '<PAD>',\n",
       " '<END>',\n",
       " '<EOF>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_native_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(ignore_index=react_native_to_index[PADDING_TOKEN],\n",
    "                                reduction='none')\n",
    "\n",
    "# When computing the loss, we are ignoring cases when the label is the padding token\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform_(params)\n",
    "\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(flutter_batch, react_batch):\n",
    "    num_sentences = len(flutter_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      flutter_sentence_length, react_sentence_length = len(flutter_batch[idx]), len(react_batch[idx])\n",
    "      flutter_tokens_to_padding_mask = np.arange(flutter_sentence_length + 1, max_sequence_length)\n",
    "      react_tokens_to_padding_mask = np.arange(react_sentence_length + 1, max_sequence_length)\n",
    "      encoder_padding_mask[idx, :, flutter_tokens_to_padding_mask] = True\n",
    "      encoder_padding_mask[idx, flutter_tokens_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, react_tokens_to_padding_mask] = True\n",
    "      decoder_padding_mask_self_attention[idx, react_tokens_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, flutter_tokens_to_padding_mask] = True\n",
    "      decoder_padding_mask_cross_attention[idx, react_tokens_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9': 0,\n",
       " 'rethrow': 1,\n",
       " ')': 2,\n",
       " 'interface': 3,\n",
       " '!': 4,\n",
       " 'do': 5,\n",
       " 'deferred': 6,\n",
       " 'function': 7,\n",
       " 'catch': 8,\n",
       " '\\t': 9,\n",
       " '2': 10,\n",
       " '6': 11,\n",
       " 'abstract': 12,\n",
       " 'operator': 13,\n",
       " '4': 14,\n",
       " 'else': 15,\n",
       " 'double': 16,\n",
       " 'native': 17,\n",
       " '=': 18,\n",
       " 'Stream': 19,\n",
       " 'finally': 20,\n",
       " 'class': 21,\n",
       " '~': 22,\n",
       " 'print': 23,\n",
       " 'main': 24,\n",
       " 'continue': 25,\n",
       " 'part': 26,\n",
       " 'const': 27,\n",
       " 'bool': 28,\n",
       " 'in': 29,\n",
       " '(': 30,\n",
       " ']': 31,\n",
       " 'implements': 32,\n",
       " 'with': 33,\n",
       " 'List': 34,\n",
       " 'Set': 35,\n",
       " 'mixin': 36,\n",
       " '.': 37,\n",
       " ';': 38,\n",
       " 'default': 39,\n",
       " 'covariant': 40,\n",
       " 'is': 41,\n",
       " 'sync': 42,\n",
       " 'varfinal': 43,\n",
       " 'library': 44,\n",
       " ',': 45,\n",
       " 'while': 46,\n",
       " 'Future': 47,\n",
       " 'super': 48,\n",
       " 'null': 49,\n",
       " '1': 50,\n",
       " 'new': 51,\n",
       " 'Function': 52,\n",
       " '<': 53,\n",
       " 'export': 54,\n",
       " 'assert': 55,\n",
       " '5': 56,\n",
       " '-': 57,\n",
       " ':': 58,\n",
       " 'yield': 59,\n",
       " 'show': 60,\n",
       " 'true': 61,\n",
       " '{': 62,\n",
       " 'false': 63,\n",
       " '\\n': 64,\n",
       " '+': 65,\n",
       " '>': 66,\n",
       " 'late': 67,\n",
       " 'external': 68,\n",
       " 'Map': 69,\n",
       " '*': 70,\n",
       " '0': 71,\n",
       " '&': 72,\n",
       " 'var': 73,\n",
       " '[': 74,\n",
       " 'await': 75,\n",
       " 'enum': 76,\n",
       " '3': 77,\n",
       " 'for': 78,\n",
       " 'void': 79,\n",
       " 'import': 80,\n",
       " 'return': 81,\n",
       " '/': 82,\n",
       " 'typedef': 83,\n",
       " 'factory': 84,\n",
       " 'this': 85,\n",
       " 'Iterable': 86,\n",
       " '8': 87,\n",
       " 'dynamic': 88,\n",
       " 'final': 89,\n",
       " 'try': 90,\n",
       " 'String': 91,\n",
       " 'break': 92,\n",
       " 'static': 93,\n",
       " '7': 94,\n",
       " ' ': 95,\n",
       " 'as': 96,\n",
       " '}': 97,\n",
       " 'set': 98,\n",
       " 'on': 99,\n",
       " 'hide': 100,\n",
       " 'switch': 101,\n",
       " 'get': 102,\n",
       " '%': 103,\n",
       " 'async': 104,\n",
       " 'int': 105,\n",
       " '|': 106,\n",
       " 'if': 107,\n",
       " 'throw': 108,\n",
       " 'extension': 109,\n",
       " 'extends': 110,\n",
       " 'case': 111,\n",
       " '?': 112,\n",
       " '<START>': 113,\n",
       " '<PAD>': 114,\n",
       " '<END>': 115,\n",
       " '<EOF>': 116}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flutter_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1008) must match the size of tensor b (200) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask \u001b[38;5;241m=\u001b[39m create_masks(flutter_batch, react_batch)\n\u001b[1;32m     13\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m react_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflutter_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mreact_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mencoder_self_attention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdecoder_self_attention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdecoder_cross_attention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menc_start_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menc_end_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdec_start_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdec_end_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m labels \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39msentence_embedding\u001b[38;5;241m.\u001b[39mbatch_tokenize(react_batch, start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterian(\n\u001b[1;32m     25\u001b[0m     react_pred\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, react_vocab_size)\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     26\u001b[0m     labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/fraimwork/backend/machine_learning/transformer.py:324\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, y, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask, enc_start_token, enc_end_token, dec_start_token, dec_end_token)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    315\u001b[0m             x, \n\u001b[1;32m    316\u001b[0m             y, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m             dec_start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# We should make this true\u001b[39;00m\n\u001b[1;32m    323\u001b[0m             dec_end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \u001b[38;5;66;03m# x, y are batch of sentences\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_self_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menc_start_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menc_end_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask, start_token\u001b[38;5;241m=\u001b[39mdec_start_token, end_token\u001b[38;5;241m=\u001b[39mdec_end_token)\n\u001b[1;32m    326\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/fraimwork/backend/machine_learning/transformer.py:199\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, self_attention_mask, start_token, end_token)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, self_attention_mask, start_token, end_token):\n\u001b[0;32m--> 199\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentence_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x, self_attention_mask)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/fraimwork/backend/machine_learning/transformer.py:93\u001b[0m, in \u001b[0;36mSnippetEmbedding.forward\u001b[0;34m(self, x, start_token, end_token)\u001b[0m\n\u001b[1;32m     91\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m     92\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_encoder()\u001b[38;5;241m.\u001b[39mto(get_device())\n\u001b[0;32m---> 93\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1008) must match the size of tensor b (200) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        flutter_batch, react_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(flutter_batch, react_batch)\n",
    "        optim.zero_grad()\n",
    "        react_pred = transformer(flutter_batch,\n",
    "                                     react_batch,\n",
    "                                     encoder_self_attention_mask.to(device), \n",
    "                                     decoder_self_attention_mask.to(device), \n",
    "                                     decoder_cross_attention_mask.to(device),\n",
    "                                     enc_start_token=False,\n",
    "                                     enc_end_token=False,\n",
    "                                     dec_start_token=True,\n",
    "                                     dec_end_token=True)\n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(react_batch, start_token=False, end_token=True)\n",
    "        loss = criterian(\n",
    "            react_pred.view(-1, react_vocab_size).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "        valid_indicies = torch.where(labels.view(-1) == react_native_to_index[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #train_losses.append(loss.item())\n",
    "        # if batch_num % 100 == 0:\n",
    "        #     print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "        #     print(f\"Flutter: {flutter_batch[0]}\")\n",
    "        #     print(f\"React Translation: {react_batch[0]}\")\n",
    "        #     kn_sentence_predicted = torch.argmax(react_pred[0], axis=1)\n",
    "        #     predicted_sentence = \"\"\n",
    "        #     for idx in kn_sentence_predicted:\n",
    "        #         if idx == react_native_to_index[END_TOKEN]:\n",
    "        #             break\n",
    "        #     predicted_sentence += react_native_vocabulary[idx.item()]\n",
    "        #     print(f\"React Prediction: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "            # transformer.eval()\n",
    "            # react_code = (\"\",)\n",
    "            # flutter_code = (\"should we go to the mall?\",)\n",
    "            # for word_counter in range(max_sequence_length):\n",
    "            #     encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(flutter_code, react_code)\n",
    "            #     predictions = transformer(flutter_code,\n",
    "            #                               react_code,\n",
    "            #                               encoder_self_attention_mask.to(device), \n",
    "            #                               decoder_self_attention_mask.to(device), \n",
    "            #                               decoder_cross_attention_mask.to(device),\n",
    "            #                               enc_start_token=False,\n",
    "            #                               enc_end_token=False,\n",
    "            #                               dec_start_token=True,\n",
    "            #                               dec_end_token=False)\n",
    "            #     next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
    "            #     next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "            #     next_token = react_native_vocabulary[next_token_index]\n",
    "            #     react_code = (react_code[0] + next_token, )\n",
    "            #     if next_token == END_TOKEN:\n",
    "            #       break\n",
    "            \n",
    "            # print(f\"Evaluation translation (should we go to the mall?) : {react_code}\")\n",
    "            # print(\"-------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
