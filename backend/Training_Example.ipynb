{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "PADDING_TOKEN = '<PAD>'\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 1\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "max_sequence_length = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flutter Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 29118\n"
     ]
    }
   ],
   "source": [
    "from pygments.lexers import DartLexer\n",
    "from utils.vocab import dart_vocab\n",
    "from utils.code_tokenizer import CodeTokenizer\n",
    "\n",
    "flutter_tokenizer = CodeTokenizer(\n",
    "    DartLexer(),\n",
    "    framework_vocab=[\"Scaffold\", \"Widget\"],\n",
    "    language_vocab=dart_vocab,\n",
    "    START_TOKEN=START_TOKEN,\n",
    "    END_TOKEN=END_TOKEN,\n",
    "    PAD_TOKEN=PADDING_TOKEN\n",
    ")\n",
    "\n",
    "print(f\"Token Count: {len(flutter_tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create React Native Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 29120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pygments.lexers import JavascriptLexer\n",
    "from utils.vocab import javascript_vocab\n",
    "from utils.code_tokenizer import CodeTokenizer\n",
    "\n",
    "react_native_tokenizer = CodeTokenizer(\n",
    "    JavascriptLexer(),\n",
    "    framework_vocab=[\"View\", \"Text\"],\n",
    "    language_vocab=javascript_vocab,\n",
    "    START_TOKEN=START_TOKEN,\n",
    "    END_TOKEN=END_TOKEN,\n",
    "    PAD_TOKEN=PADDING_TOKEN,\n",
    ")\n",
    "\n",
    "print(f\"Token Count: {len(react_native_tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Letter Tokenizer\n",
    "For debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 100\n"
     ]
    }
   ],
   "source": [
    "from utils.code_tokenizer import CodeTokenizer\n",
    "\n",
    "letter_tokenizer = CodeTokenizer(\n",
    "    None,\n",
    "    framework_vocab=[],\n",
    "    language_vocab=[\n",
    "        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "        'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'\n",
    "        '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '{', '}', '(', ')',\n",
    "        '[', ']', '=', '+', '-', '*', '/', '%', '^', '&', '|', '!', '?', '<',\n",
    "        '>', ':', ';', ',', '.', '_', '#', '@', '$', '~', '`', '\"', \"'\", '\\\\',\n",
    "        '/', '\\n', ' ', '\\t', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "        'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "        'W', 'X', 'Y', 'Z'\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Token Count: {len(letter_tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SnippetEmbedding(\n",
       "      (embedding): Embedding(29118, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SnippetEmbedding(\n",
       "      (embedding): Embedding(29120, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm3): LayerNormalization()\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=29120, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.transformer import Transformer\n",
    "\n",
    "transformer = Transformer(\n",
    "    d_model, \n",
    "    ffn_hidden,\n",
    "    num_heads, \n",
    "    drop_prob, \n",
    "    num_layers, \n",
    "    max_sequence_length,\n",
    "    flutter_tokenizer,\n",
    "    react_native_tokenizer,\n",
    "    START_TOKEN, \n",
    "    END_TOKEN, \n",
    "    PADDING_TOKEN\n",
    ")\n",
    "\n",
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, flutter_snippets, react_snippets):\n",
    "        self.flutter_snippets = flutter_snippets\n",
    "        self.react_snippets = react_snippets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flutter_snippets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.flutter_snippets[idx], self.react_snippets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dart samples: 80\n",
      "Number of JS samples: 80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/raw/samples.csv')\n",
    "\n",
    "dart_samples = df['dart'].values\n",
    "js_samples = df['javascript'].values\n",
    "\n",
    "# filter for max length of sample at `max_sequence_len`` characters for training purposes\n",
    "zipped = list(zip(dart_samples, js_samples))\n",
    "samples = [(d[:max_sequence_length-2], j[:max_sequence_length-2]) for d, j in zipped if len(d) >= max_sequence_length and len(j) >= max_sequence_length]\n",
    "dart_samples, js_samples = zip(*samples)\n",
    "\n",
    "print(\"Number of Dart samples:\", len(dart_samples))\n",
    "print(\"Number of JS samples:\", len(js_samples))\n",
    "\n",
    "dataset = TextDataset(dart_samples, js_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(ignore_index=react_native_tokenizer[PADDING_TOKEN], reduction='none')\n",
    "\n",
    "# When computing the loss, we are ignoring cases when the label is the padding token\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform_(params)\n",
    "\n",
    "optim = torch.optim.AdamW(transformer.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(flutter_batch, react_batch):\n",
    "    num_sentences = len(flutter_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "        flutter_sentence_length, react_sentence_length = len(flutter_batch[idx]), len(react_batch[idx])\n",
    "        flutter_tokens_to_padding_mask = np.arange(flutter_sentence_length + 1, max_sequence_length)\n",
    "        react_tokens_to_padding_mask = np.arange(react_sentence_length + 1, max_sequence_length)\n",
    "        encoder_padding_mask[idx, :, flutter_tokens_to_padding_mask] = True\n",
    "        encoder_padding_mask[idx, flutter_tokens_to_padding_mask, :] = True\n",
    "        decoder_padding_mask_self_attention[idx, :, react_tokens_to_padding_mask] = True\n",
    "        decoder_padding_mask_self_attention[idx, react_tokens_to_padding_mask, :] = True\n",
    "        decoder_padding_mask_cross_attention[idx, :, flutter_tokens_to_padding_mask] = True\n",
    "        decoder_padding_mask_cross_attention[idx, react_tokens_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:42<00:00,  4.25s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        flutter_batch, react_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(flutter_batch, react_batch)\n",
    "        optim.zero_grad()\n",
    "        react_pred = transformer(\n",
    "            flutter_batch,\n",
    "            react_batch,\n",
    "            encoder_self_attention_mask.to(device), \n",
    "            decoder_self_attention_mask.to(device), \n",
    "            decoder_cross_attention_mask.to(device),\n",
    "            enc_start_token=False,\n",
    "            enc_end_token=False,\n",
    "            dec_start_token=True,\n",
    "            dec_end_token=True\n",
    "        )\n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(react_batch, start_token=False, end_token=True)\n",
    "        loss = criterian(\n",
    "            react_pred.view(-1, len(react_native_tokenizer)).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "        valid_indicies = torch.where(labels.view(-1) == react_native_tokenizer[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #train_losses.append(loss.item())\n",
    "        # if batch_num % 100 == 0:\n",
    "        #     print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "        #     print(f\"Flutter: {flutter_batch[0]}\")\n",
    "        #     print(f\"React Translation: {react_batch[0]}\")\n",
    "        #     kn_sentence_predicted = torch.argmax(react_pred[0], axis=1)\n",
    "        #     predicted_sentence = \"\"\n",
    "        #     for idx in kn_sentence_predicted:\n",
    "        #         if idx == react_native_to_index[END_TOKEN]:\n",
    "        #             break\n",
    "        #     predicted_sentence += react_native_vocabulary[idx.item()]\n",
    "        #     print(f\"React Prediction: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "            # transformer.eval()\n",
    "            # react_code = (\"\",)\n",
    "            # flutter_code = (\"should we go to the mall?\",)\n",
    "            # for word_counter in range(max_sequence_length):\n",
    "            #     encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(flutter_code, react_code)\n",
    "            #     predictions = transformer(flutter_code,\n",
    "            #                               react_code,\n",
    "            #                               encoder_self_attention_mask.to(device), \n",
    "            #                               decoder_self_attention_mask.to(device), \n",
    "            #                               decoder_cross_attention_mask.to(device),\n",
    "            #                               enc_start_token=False,\n",
    "            #                               enc_end_token=False,\n",
    "            #                               dec_start_token=True,\n",
    "            #                               dec_end_token=False)\n",
    "            #     next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
    "            #     next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "            #     next_token = react_native_vocabulary[next_token_index]\n",
    "            #     react_code = (react_code[0] + next_token, )\n",
    "            #     if next_token == END_TOKEN:\n",
    "            #       break\n",
    "            \n",
    "            # print(f\"Evaluation translation (should we go to the mall?) : {react_code}\")\n",
    "            # print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flutter Code: double x = 10;\n",
      "React Translation: ('<START><START>varvarvarvarList##S##S=',)\n"
     ]
    }
   ],
   "source": [
    "transformer.eval()\n",
    "# predict the translation of a flutter code snippet\n",
    "flutter_code = \"double x = 10;\"\n",
    "print(f\"Flutter Code: {flutter_code}\")\n",
    "\n",
    "flutter_code = (flutter_code,)\n",
    "react_code = (\"\",)\n",
    "for word_counter in range(max_sequence_length-50):\n",
    "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(flutter_code, react_code)\n",
    "    predictions = transformer(\n",
    "        flutter_code,\n",
    "        react_code,\n",
    "        encoder_self_attention_mask.to(device), \n",
    "        decoder_self_attention_mask.to(device), \n",
    "        decoder_cross_attention_mask.to(device),\n",
    "        enc_start_token=False,\n",
    "        enc_end_token=False,\n",
    "        dec_start_token=True,\n",
    "        dec_end_token=False\n",
    "    )\n",
    "    next_token_prob_distribution = predictions[0][word_counter]\n",
    "    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "    next_token = react_native_tokenizer.get_token(next_token_index)\n",
    "    react_code = (react_code[0] + next_token, )\n",
    "    if next_token == END_TOKEN:\n",
    "        break\n",
    "print(f\"React Translation: {react_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(transformer.state_dict(), './models/transformer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Clear cache\n",
    "gc.collect()\n",
    "\n",
    "# Clear garbage collector\n",
    "gc.garbage.clear()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
